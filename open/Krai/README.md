# MLPerf Inference v4.1 - KRAI ONNXRT submissions

KRAI present Edge submissions using ONNX Runtime with CPU/GPU backends.

The submissions use the [KRAI](https://krai.ai) [KILT](http://github.com/krai/kilt-mlperf)
technology for fast, efficient and scalable inference, and the
[KRAI X](http://github.com/krai/axs) technology for workflow automation.

Detailed setup instructions per benchmark are provided in README files under the
[code](code) directory.  Individual benchmarking commands per system,
benchmark, scenario and mode are provided in README files under the respective
[measurements](measurements) directories.

The source code has been released under the permissive MIT license across
several public repositories (under the `mlperf_4.1` branches created by the
v4.1 submission deadline):

- https://github.com/krai/kilt-mlperf (KRAI Inference Library Technology for MLPerf submissions)
- https://github.com/krai/axs (KRAI X Workflow Automation Technology)
- https://github.com/krai/axs2onnxrt
- https://github.com/krai/axs2mlperf
- https://github.com/krai/axs2system

## Contact

For any queries please contact info@krai.ai.
