{
  "accelerator_frequency": "",
  "accelerator_host_interconnect": "PCIe Gen5 x16",
  "accelerator_interconnect": "18x 4th Gen NVLink, 900GB/s",
  "accelerator_interconnect_topology": "",
  "accelerator_memory_capacity": "80 GB",
  "accelerator_memory_configuration": "HBM3",
  "accelerator_model_name": "NVIDIA H100-SXM-80GB",
  "accelerator_on-chip_memories": "",
  "accelerators_per_node": "4",
  "cooling": "air",
  "division": "open",
  "framework": "vLLM 0.5.2",
  "host_memory_capacity": "2.1T",
  "host_memory_configuration": "undefined",
  "host_network_card_count": "1",
  "host_networking": "Gig Ethernet",
  "host_networking_topology": "N/A",
  "host_processor_caches": "L1d cache: 3 MiB (64 instances), L1i cache: 2 MiB (64 instances), L2 cache: 128 MiB (64 instances), L3 cache: 120 MiB (2 instances)",
  "host_processor_core_count": "32",
  "host_processor_frequency": "4100.0000",
  "host_processor_interconnect": "",
  "host_processor_model_name": "Intel(R) Xeon(R) Platinum 8462Y+",
  "host_processors_per_node": "2",
  "host_storage_capacity": "15T",
  "host_storage_type": "SSD",
  "hw_notes": "",
  "number_of_nodes": "1",
  "operating_system": "Ubuntu 22.04 (linux-6.5.0-35-generic-glibc2.35)",
  "other_software_stack": "Python: 3.10.12, LLVM-15.0.6",
  "status": "available",
  "submitter": "NeuralMagic",
  "sw_notes": "Automated by MLCommons CM v2.3.4. ",
  "system_name": "SYS-821GE-TNHR H100 'beaker' (4x H100-SXM-80GB, vLLM, FP8)",
  "system_type": "datacenter",
  "system_type_detail": ""
}
