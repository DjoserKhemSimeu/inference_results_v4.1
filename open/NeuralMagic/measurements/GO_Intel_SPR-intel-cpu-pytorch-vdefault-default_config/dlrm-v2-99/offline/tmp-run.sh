#!/bin/bash

export CM_GIT_CHECKOUT_PATH="/home/arjun/CM/repos/local/cache/63945a551f734a2c/repo"
export CM_GIT_REPO_CHECKOUT=""
export CM_GIT_REPO_CHECKOUT_FOLDER="repo"
export CM_GIT_REPO_CHECKOUT_PATH="/home/arjun/CM/repos/local/cache/63945a551f734a2c/repo"
export CM_GIT_REPO_CURRENT_HASH="8fec21f555d504308b7fac616bdadb6961068c2a"
export CM_GIT_REPO_DEPTH="--depth 5"
export CM_GIT_REPO_NAME="mlperf_inference_submissions_v4.1"
export CM_GIT_REPO_PATCH="no"
export CM_GIT_REPO_RECURSE_SUBMODULES=" --recurse-submodules"
export CM_GIT_REPO_URL="https://github.com/neuralmagic/mlperf_inference_submissions_v4.1"
export CM_MLPERF_INFERENCE_SUBMISSION_DIR="/home/arjun/CM/repos/local/cache/78b4b7bcbea34388/mlperf-inference-submission"
export CM_MLPERF_INFERENCE_SUBMISSION_VERSION="4_1"
export CM_MLPERF_RESULTS_GIT_REPO_URL="https://github.com/neuralmagic/mlperf_inference_submissions_v4.1"
export CM_MLPERF_RESULTS_REPO_COMMIT_MESSAGE="Results on Intel SPR (2x4090)"
export CM_PYTHON_BIN="python3"
export CM_PYTHON_BIN_PATH="/home/arjun/cm/bin"
export CM_PYTHON_BIN_WITH_PATH="/home/arjun/cm/bin/python3"
export CM_PYTHON_CACHE_TAGS="version-3.11.4,non-virtual"
export CM_PYTHON_MAJOR_VERSION="3"
export CM_PYTHON_MINOR_VERSION="11"
export CM_PYTHON_PATCH_VERSION="4"
export CM_PYTHON_VERSION="3.11.4"
export CM_QUIET="yes"
export CM_TMP_CURRENT_PATH="/home/arjun/CM/repos/local/cache/78b4b7bcbea34388/mlperf-inference-submission/open/NeuralMagic/measurements/GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config/dlrm-v2-99/offline"
export CM_TMP_CURRENT_SCRIPT_PATH="/home/arjun/CM/repos/gateoverflow@cm4mlops/script/push-mlperf-inference-results-to-github"
export CM_TMP_CURRENT_SCRIPT_REPO_PATH="/home/arjun/CM/repos/gateoverflow@cm4mlops"
export CM_TMP_CURRENT_SCRIPT_REPO_PATH_WITH_PREFIX="/home/arjun/CM/repos/gateoverflow@cm4mlops"
export CM_TMP_CURRENT_SCRIPT_WORK_PATH="/home/arjun/CM/repos/local/cache/78b4b7bcbea34388/mlperf-inference-submission/open/NeuralMagic/measurements/GO_Intel_SPR-intel-cpu-pytorch-vdefault-default_config/dlrm-v2-99/offline"
export CM_TMP_PIP_VERSION_STRING=""


. "/home/arjun/CM/repos/gateoverflow@cm4mlops/script/push-mlperf-inference-results-to-github/run.sh"
